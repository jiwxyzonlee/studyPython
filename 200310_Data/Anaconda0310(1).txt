

** 단계구분도(chropleth)
- 지도에 색상을 추가해서 시각화하는 것
- 데이터와 영역의 경계를 나타내는 json 파일이 필요
- 우리나라 영역의 경계는 southkorea-maps에서 확인이 가능
- 단계구분도에 각 영역의 크기를 왜곡해서 모두 동일한 크기로 보여주도록 하는 것은 엑셀이나 svg를 이용해서 작업함


* 인덱스는 문자열로 만드는 것이 일반적

- 우리나라 경제 관련 데이터
: https://github.com/southkorea/southkorea-maps


** pandas의 시각화
- pandas는 matplotlib의 기능 일부분을 소유
- Dataframe이나 Series 객체를 가지고 plot일는 메소드를 호출하면 그래프를 그릴 수 있음
- kind 옵션에 그래프 종류 설정

line
: 선그래프

bar
: 수직 막대 그래프

barh
: 수평 막대 그래프

hist
: 히스토그램

box
: 상자그래프

kde
: 커널 밀도 그래프

area
: 면적 그래프

pie
: 원 그래프

scatter
: 산포도 - 산점도

hexbin
: 고밀도 산점도 그래프
->> 세밀한 옵션 조정이 안 돼서 데이터 탐색을 할 때는 사용하는 경우가 있기는 하지만 시각화하는 용도로는 잘 사용하지 않음



** 데이터 가공
: 패키지가 제공하는 데이터는 load_dataset('데이터이름')을 이용하면 데이터프레임이나 패키지에서 제공하는 별도의 클래스 타입으로 데이터가 다운로드 됨
->> 인터넷이 안되면 데이터를 사용할 수 없음

- 대기업이나 금융기관은 인터넷은 되지만 데이터는 함부로 다운로드 받거나 설치할 수 없도록 설정된 경우가 있음
->> 이런 경우에도 데이터는 다운로드가 안 됨


1. 셀의 데이터 수정
- replace 이용
- 첫번째 매개변수로 원본 데이터를 대입하고 두번째 매개변수로 수정할 데이터를 설정
- dict로 원본데이터와 수정할 데이터를 설정
replace(1, 2)
replace({1:2})
- 원본 데이터에 정규식을 사용할 수 있는데 이 경우에는 regex = True를 추가
->> 텍스트 마이닝을 하고자 하는 경우에는 정규식을 학습해야 함
- 여러 개의 데이터를 수정하고자 하는 경우 list로 대입해도 됨


2. 결측치 처리
- 결측치
: 존재하지 않는 데이터로 파이썬에서 None이고 numpy에서 numpy.NaN으로 표현
- 결측치와의 연산 결과도 None
- read_csv 메소드에서 na_values 옵션을 이용해서 None으로 처리할 list를 대입할 수 있음

1) Dataframe의 null 관련 메소드
isnull()
: None 데이터인 경우 True, 아니면 False

notnull()
: isnull()의 반대

dropna()
: NaN 값을 소유한 행을 제거, axis = 1 옵션을 추가하면 열 제거
->> how 매개변수에 all을 대입시 모든 데이터가 None인 경우만 제거
->> thresh 매개변수에 정수 대입 시 입력 개수보다 많은 None을 가진 경우만 제거

fillna()
: NaN 값을 소유한 데이터를 다른 값으로 치환
->> 값을 직접 입력할 수도 있고 methon 매개변수에 ffill 등과 같은 값을 설정해서 앞이나 뒤의 값으로 채울 수 있음

2) 결측치 처리 방식
- 결측치가 많은 열의 경우 열 제거
- 결측치가 아주 많지 않은 경우 결측치를 가진 행만 제거
- 결측치를 가진 데이터를 삭제하기 애매한 경우(결측치가 몇 개 안되거나 어쩔 수 없이 결측치가 발생하는 경우)에는 결측치를 다른 값으로 치환함
->> 다른 값으로 치환하는 경우에는 최빈값(가장 자주 나오는 값), 평균, 중간값 등을 사용하는 방식이 있고 머신러닝을 이용해서 가장 비슷한 데이터의 값으로 채우는 방법이 있음
->> 머신러닝을 이용해서 값을 채우는 것이 가장 좋지만 이 방법은 시간이 오래 걸리기 때문에 데이터가 아주 많은 경우 사용하기가 곤란

3) 결측값 대치
- 사이킷 런의 SimpleImputer 클래스를 이용해서 최빈값이나 평균 및 중간값 등으로 채울 수 있음

4) 머신 러닝을 이용한 결측값 대치
- fancyimpute 패키지 이용
- 설치 도중 아래와 같은 에러가 발생 시 (윈도우즈에서만 발생)
error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": https://visualstudio.microsoft.com/downloads/

google에서 Visual C++ 14.0 재배포 패키지를 검색하여 다운로드 받은 후 설치하고 다시 설치하면 됨
- 패키지 만들 때 Visual C++에서 만들어서 배포하기 때문에 이런 현상이 발생함


3. 중복 데이터 처리
- 하나의 데이터 셋에서 중복된 데이터가 존재한다면 제거하는 것이 좋음
->> 동일한 데이터가 여러 개 존재한다면 머신러닝이나 딥러닝을 수행할 때 결과 왜곡 발생 주의

duplicated()
: 데이터의 중복여부를 리턴해주는 메소드
drop_duplicates()
: 중복된 데이터 제거
->> 기본은 모든 컬럼의 값이 같은 경우에 제거
->> subset옵션은 컬럼이름의 list를 대입 시 컬럼이름에 해당하는 값들이 같은 경우
->> 첫번째 데이터를 남기고 나머지 데이터를 삭제하는 데 keep 옵션 이용 시 다른 데이터를 남길 수도 있음
- 이런 상황은 여러 개의 데이터 셋을 하나로 합칠 때 많이 발생



** 데이터 표준화
: 여러 곳에서 수집한 데이터들은 단위나 대소문자 구분 또는 약자 활용들으로 인해 바로 사용할 수 없을 수 있음
- 이런 경우 단위나 대소문자 구분 등을 통일할 필요가 있음
->> 표준화 작업


1. 단위가 다른 경우에는 반드시 단위는 통일시켜야 함


2. 자료형 변환
- 데이터를 수집할 때는 자료형을 고려하지 않고 수집을 하지만 분석이나 머신러닝 등에 적용할 때 적용하고자 하는 알고리즘에 맞게 데이터의 자료형을 수정해야 함
->> 분류할 때는 숫자 데이터가 아니라 범주형이 필요
->> 머신러닝으로 거리 계산 시 문자 데이터의 경우 거리 계산이 불가하므로 숫자 데이터로 변환해야 함


3. 연속형 데이터의 이산화
- 연속적인 데이터를 가지고 분류한다면 데이터 변환 없이 할 시 그룹 종류가 너무 많아지게 됨
- 연속적인 데이터를 몇 개의 구간으로 나누는 이산화 작업을 해야 함
->> 구간분할(binning)
- pandas의 cut 함수를 이용
->> x에 데이터 배열을 설정
->> bins에 경계값 배열을 설정
->> labels에 변환할 이산 데이터 배열을 설정
->> include_lowest에 True를 설정하면 첫번째 경계값을 포함

2) numpy의 digitize 이용
- 첫번째 매개변수는 분할할 데이터
- bins에 구간을 분할할 값의 리스트를 대입함
- right에 구간을 포함할지 여부를 bool로 설정
- 각 구간에는 0, 1, 2 형태의 일련번호를 배정해서 그 결과를 배열로 리턴

3) 여러 개의 열로 구성된 데이터를 이산화해야 하는 경우
- 군집 분석 알고리즘을 이용