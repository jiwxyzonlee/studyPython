**단계구분도(choropleth)
=>지도에 색상을 추가해서 시각화하는 것
=>데이터와 영역의 경계를 나타내는 json 파일이 필요
=>우리나라 영역의 경계는 southkorea-maps 에서 확인이 가능
=>단계구분도에 각 영역의 크기를 왜곡해서 모두 동일한 크기로 보여주도록 하는 것은 엑셀이나 svg를 이용해서 작업합니다.
=>우리나라 경계 관련 데이터: https://github.com/southkorea/southkorea-maps

**pandas의 시각화
=>pandas는 matplotlib 의 기능 일부분을 소유
=>Dataframe 이나 Series 객체를 가지고 plot 이라는 메소드를 호출하면 그래프를 그릴 수 있습니다. 
=>kind 옵션에 그래프 종류를 설정하면 됩니다.
line: 선그래프
bar: 수직 막대 그래프
barh: 수평 막대 그래프
hist: 히스토그램
box: 상자 그래프
kde: 커널 밀도 그래프
area: 면적 그래프
pie: 원 그래프
scatter: 산포도- 산점도
hexbin: 고밀도 산점도 그래프
=>세밀한 옵션 조정이 안되서 데이터 탐색을 할 때는 사용하는 경우가 있기는 하지만 시각화하는 용도로는 잘 사용하지 않음

**데이터 가공
=>패키지가 제공하는 데이터는 load_dataset('데이터이름')을 이용하면 데이터프레임이나 패키지에서 제공하는 별도의 클래스 타입으로 데이터가 다운로드 됩니다.
인터넷이 안되면 데이터를 사용할 수 없습니다.
=>대기업이나 금융기관은 인터넷은 되지만 데이터는 함부로 다운로드 받거나 설치할 수 없도록 설정된 경우가 있습니다.
이런 경우에도 데이터는 다운로드가 안됩니다.

1.셀의 데이터 수정
=>replace 이용
=>첫번째 매개변수로 원본 데이터를 대입하고 두번째 매개변수로 수정할 데이터를 설정
=>dict로 원본데이터와 수정할 데이터를 설정
replace(1,2)
replace({1:2})
=>원본 데이터에 정규식을 사용할 수 있는데 이 경우에는 regex=True를 추가
텍스트 마이닝을 하고자 하는 경우에는 정규식을 학습할 필요가 있습니다.
=>여러 개의 데이터를 수정하고자 하는 경우에는 list로 대입해도 됩니다.

2.결측치 처리
=>결측치: 존재하지 않는 데이터로 파이썬에서는 None 이고 numpy에서는 numpy.NaN 으로 표현
=>결측치와의 연산 결과는 None입니다.
=>read_csv 메소드에는 na_values 옵션을 이용해서 None으로 처리할 list를 대입할 수 있습니다.

1)Dataframe의 null 관련 메소드
=>isnull(): None 데이터인 경우는 True 그렇지 않으면 False
notnull 은 반대
=>dropna(): NaN 값을 소유한 행을 제거하고 axis = 1 옵션을 추가하면 열을 제거
how 매개변수에 all을 대입하면 모든 데이터가 NaN 경우만 제거
thresh 매개변수에 정수를 대입하면 이 개수보다 많은 NaN 을 가진 경우만 제거
=>fillna(): NaN 값을 소유한 데이터를 다른 값으로 치환하는 함수
값을 직접 입력할 수 있고 methon 매개변수에 ffill 등과 같은 값을 설정해서 앞이나 뒤의 값으로 채울 수 있습니다.

2)결측치 처리 방식
=>결측치가 많은 열의 경우는 열을 제거합니다.
=>결측치가 아주 많지 않은 경우는 결측치를 가진 행만 제거합니다.
=>결측치를 가진 데이터를 삭제하기 애매한 경우(결측치가 몇개 안되거나 어쩔수 없이 결측치가 발생하는 경우)에는 결측치를 다른 값으로 치환을 합니다.
다른 값으로 치환하는 경우에는 최빈값(가장 자주 나오는 값), 평균, 중간값 등을 사용하는 방식이 있고 머신러닝을 이용해서 가장 비슷한 데이터의 값으로 채우는 방법이 있습니다.
머신러닝을 이용해서 값을 채우는 것이 가장 좋지만 이 방법은 시간이 오래 걸리기 때문에 데이터가 아주 많은 경우는 사용하기가 곤란합니다.

3)결측값 대치
=>사이킷 런의 SimpleImputer 클래스를 이용해서 최빈값이나 평균 및 중간값 등으로 채울 수 있습니다.

4)머신러닝을 이용한 결측값 대치
fancyimpute 패키지 이용

fancyimpute 설치 도중 아래와 같은 에러가 발생하면 
error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": https://visualstudio.microsoft.com/downloads/

google.com에서 Visual C++ 14.0 재배포 패키지를 검색해서 다운로드 받은 후 설치하고 다시 설치하면 됩니다.
이 에러는 Windows에서만 발생
패키지를 만들 때 Visual C++ 에서 만들어서 배포를 해서 이런 현상이 발생

3.중복 데이터 처리
=>하나의 데이터 셋에서 중복된 데이터가 존재한다면 제거하는 것이 좋습니다.
동일한 데이터가 여러 개 존재하면 머신러닝이나 딥러닝을 수행할 때 결과가 왜곡 될 수 있습니다.
=>관련 함수
duplicated(): 데이터의 중복여부를 리턴해주는 메소드
drop_duplicates(): 중복된 데이터 제거
                         기본은 모든 컬럼의 값이 같은 경우에 제거
                         subset 옵션에 컬럼이름의 list를 대입하면 컬럼이름에 해당하는 값들이 같은 경우에 제거
                        첫번째 데이터를 남기고 나머지 데이터를 삭제하는데 keep 옵션을 이용하면 다른 데이터를 남길 수 도 있습니다.
=>이런 상황은 여러 개의 데이터셋을 하나로 합칠 때 많이 발생합니다.

**데이터 표준화
=>여러 곳에서 수집한 데이터들은 단위나 대소문자 구분 또는 약자 활용들으로 인해 바로 사용하기 어려운 경우가 발생할 수 있습니다.
=>이런 경우에는 단위나 대소문자 구분 등을 통일할 필요가 있습니다.
=>이런 작업을 표준화라고 합니다.

1.단위가 다른 경우에는 반드시 단위는 통일을 시켜야 합니다.

2.자료형 변환
=>데이터를 수집할 때는 자료형을 고려하지 않고 수집을 하지만 분석이나 머신러닝등에 적용을 할 때 적용하고자 하는 알고리즘에 맞게 데이터의 자료형을 수정을 해야 합니다.
분류를 할 때는 숫자 데이터가 아니라 범주형이 필요하고 머신러닝에서 거리를 계산할려고 하는 경우에는 문자 데이터의 경우는 거리 계산이 안되므로 숫자 데이터로 변환을 해야 합니다.
자료형 변환은 astype('자료형')으로 가능

3.연속형 데이터의 이산화
=>연속적인 데이터를 가지고 분류를 한다면 데이터 변환없이 하게 되면 그룹의 종류가 너무 많아집니다.
이런 경우에는 연속적인 데이터를 몇 개의 구간으로 이산화를 해야 합니다.
이를 구간분할(binning)이라고 합니다.
1)pandas의 cut 함수를 이용
x 에 데이터 배열을 설정
bins 에 경계값 배열을 설정
labels에 변환할 이산 데이터 배열을 설정
include_lowest 에 True를 설정하면 첫번째 경계값을 포함

2)numpy의 digitize 이용
=>첫번째 매개변수는 분할할 데이터
=>bins 에 구간을 분할할 값의 list를 대입
=>right에 구간을 포함할 지 여부를 bool로 설정
=>각 구간에 0, 1, 2, 형태의 일련번호를 배정해서 그 결과를 배열로 리턴

3)여러 개의 열로 구성된 데이터를 이산화해야 하는 경우
=>군집 분석 알고리즘을 이용

**범주형 데이터의 사용
1.원 핫 인코딩
=>카테고리를 나타내는 문자열 형태의 데이터는 머신러닝에 바로 사용할 수 없습니다.
머신러닝의 대다수 알고리즘은 숫자 데이터에서만 동작을 수행하기 때문입니다.
카테고리 형태의 데이터를 특성의 소유 여부만을 나타내는 0과 1로 변환하는 작업을 원핫인코딩이라고 합니다.
=>pandas 의 get_dummies()라는 함수를 이용해서 원핫 인코딩을 할 수 있는데 컬럼에 나올 수 있는 모든 값들을 조사해서 새로운 더미변수(열)를 만들고 속성을 소유하고 있으면 1 없으면 0으로 표기

2.사이킷 런의 원 핫 인코딩 
=>preprocessing.LabelBinarizer: 하나의 특성을 원 핫 인코딩
fit_transform 메소드에 데이터를 대입하면 원 핫 인코딩을 해주고 그 결과를 가지고 inverse_transform 메소드에 대입하면 원래의 데이터로 환원이 됩니다.
classes_ 속성을 확인하면 인코딩 순서를 확인할 수 있습니다.

=>preprocessing.MultiLabelBinarizer: 여러 개의 특성을 원 핫 인코딩

=>preprocessing.LabelEncoder: 0부터 시작하는 정수로 변환

=>preprocessing.OneHotEncoder: 결과를 희소행렬로 리턴해주는 sparse=False를 설정하면 밀집행렬로 리턴

3.순서가 있는 범주형 인코딩
=>순서가 있는 경우에는 replace 메소드를 이용해서 수치값으로 변환
=>일반적으로 일련번호처럼 숫자를 부여하지만 특별한 경우에는 일정 비율을 연산해서 부여하기도 합니다.
=>이와 유사한 기능을 sklearn 의 OrdinalEncoder를 이용할 수 있음

4.범주형 데이터에서 누락된 값 대체
=>가장 자주 등장하는 값을 누락된 값에 대체
=>머신러닝 알고리즘을 이용해서 구한 값으로 대체











